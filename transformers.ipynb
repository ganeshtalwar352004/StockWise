{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install yfinance","metadata":{"id":"AJOLtEZ04sYU","execution":{"iopub.status.busy":"2024-06-19T02:51:20.353196Z","iopub.execute_input":"2024-06-19T02:51:20.353654Z","iopub.status.idle":"2024-06-19T02:51:32.665847Z","shell.execute_reply.started":"2024-06-19T02:51:20.353619Z","shell.execute_reply":"2024-06-19T02:51:32.664702Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Requirement already satisfied: yfinance in /opt/conda/lib/python3.10/site-packages (0.2.40)\nRequirement already satisfied: pandas>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2.2.1)\nRequirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.10/site-packages (from yfinance) (1.26.4)\nRequirement already satisfied: requests>=2.31 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2.32.3)\nRequirement already satisfied: multitasking>=0.0.7 in /opt/conda/lib/python3.10/site-packages (from yfinance) (0.0.11)\nRequirement already satisfied: lxml>=4.9.1 in /opt/conda/lib/python3.10/site-packages (from yfinance) (5.2.2)\nRequirement already satisfied: platformdirs>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from yfinance) (3.11.0)\nRequirement already satisfied: pytz>=2022.5 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2023.3.post1)\nRequirement already satisfied: frozendict>=2.3.4 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2.4.4)\nRequirement already satisfied: peewee>=3.16.2 in /opt/conda/lib/python3.10/site-packages (from yfinance) (3.17.5)\nRequirement already satisfied: beautifulsoup4>=4.11.1 in /opt/conda/lib/python3.10/site-packages (from yfinance) (4.12.2)\nRequirement already satisfied: html5lib>=1.1 in /opt/conda/lib/python3.10/site-packages (from yfinance) (1.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\nRequirement already satisfied: six>=1.9 in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, Add, GlobalAveragePooling1D\n\nimport yfinance as yf","metadata":{"execution":{"iopub.status.busy":"2024-06-19T02:51:32.667943Z","iopub.execute_input":"2024-06-19T02:51:32.668260Z","iopub.status.idle":"2024-06-19T02:51:32.674079Z","shell.execute_reply.started":"2024-06-19T02:51:32.668230Z","shell.execute_reply":"2024-06-19T02:51:32.673083Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def calculate_bollinger_bands(data, window=10, num_of_std=2):\n    \"\"\"Calculate Bollinger Bands\"\"\"\n    rolling_mean = data.rolling(window=window).mean()\n    rolling_std = data.rolling(window=window).std()\n    upper_band = rolling_mean + (rolling_std * num_of_std)\n    lower_band = rolling_mean - (rolling_std * num_of_std)\n    return upper_band, lower_band\n\ndef calculate_rsi(data, window=10):\n    \"\"\"Calculate Relative Strength Index\"\"\"\n    delta = data.diff()\n    gain = delta.clip(lower=0)\n    loss = -delta.clip(upper=0)\n    avg_gain = gain.rolling(window=window, min_periods=1).mean()\n    avg_loss = loss.rolling(window=window, min_periods=1).mean()\n    rs = avg_gain / avg_loss\n    rsi = 100 - (100 / (1 + rs))\n    return rsi\n\ndef calculate_roc(data, periods=10):\n    \"\"\"Calculate Rate of Change.\"\"\"\n    roc = ((data - data.shift(periods)) / data.shift(periods)) * 100\n    return roc","metadata":{"id":"ziguS6k842Uo","execution":{"iopub.status.busy":"2024-06-19T02:51:32.675385Z","iopub.execute_input":"2024-06-19T02:51:32.675676Z","iopub.status.idle":"2024-06-19T02:51:32.685425Z","shell.execute_reply.started":"2024-06-19T02:51:32.675652Z","shell.execute_reply":"2024-06-19T02:51:32.684529Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"tickers = ['META', 'AAPL', 'MSFT', 'AMZN', 'GOOG']","metadata":{"id":"RS9sQ0rD6RkC","execution":{"iopub.status.busy":"2024-06-19T02:51:32.687170Z","iopub.execute_input":"2024-06-19T02:51:32.687426Z","iopub.status.idle":"2024-06-19T02:51:32.697837Z","shell.execute_reply.started":"2024-06-19T02:51:32.687403Z","shell.execute_reply":"2024-06-19T02:51:32.696786Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"ticker_data_frames = []\nstats = {}\nfor ticker in tickers:\n\n    # Download historical data for the ticker\n    data = yf.download(ticker, period=\"1mo\", interval=\"5m\")\n\n    # Calculate the daily percentage change\n    close = data['Close']\n    upper, lower = calculate_bollinger_bands(close, window=14, num_of_std=2)\n    width = upper - lower\n    rsi = calculate_rsi(close, window=14)\n    roc = calculate_roc(close, periods=14)\n    volume = data['Volume']\n    diff = data['Close'].diff(1)\n    percent_change_close = data['Close'].pct_change() * 100\n\n    # Create a DataFrame for the current ticker and append it to the list\n    ticker_df = pd.DataFrame({\n        ticker+'_close': close,\n        ticker+'_width': width,\n        ticker+'_rsi': rsi,\n        ticker+'_roc': roc,\n        ticker+'_volume': volume,\n        ticker+'_diff': diff,\n        ticker+'_percent_change_close': percent_change_close,\n    })\n\n    MEAN = ticker_df.mean()\n    STD = ticker_df.std()\n\n    # Keep track of mean and std\n    for column in MEAN.index:\n      stats[f\"{column}_mean\"] = MEAN[column]\n      stats[f\"{column}_std\"] = STD[column]\n\n    # Normalize the training features\n    ticker_df = (ticker_df - MEAN) / STD\n\n    ticker_data_frames.append(ticker_df)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MxDXk9uu6VBI","outputId":"f4fadfe5-d8d9-4f4a-ca30-ec1d49b8c17a","execution":{"iopub.status.busy":"2024-06-19T02:51:32.699185Z","iopub.execute_input":"2024-06-19T02:51:32.699479Z","iopub.status.idle":"2024-06-19T02:51:33.978743Z","shell.execute_reply.started":"2024-06-19T02:51:32.699455Z","shell.execute_reply":"2024-06-19T02:51:33.977741Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"[*********************100%%**********************]  1 of 1 completed\n[*********************100%%**********************]  1 of 1 completed\n[*********************100%%**********************]  1 of 1 completed\n[*********************100%%**********************]  1 of 1 completed\n[*********************100%%**********************]  1 of 1 completed\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert stats from dict to df\nstats = pd.DataFrame([stats], index=[0])\nstats.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"id":"PoLOIDNN6jFB","outputId":"c717de95-e159-4d25-bb6b-2576b75c8f90","execution":{"iopub.status.busy":"2024-06-19T02:51:37.897009Z","iopub.execute_input":"2024-06-19T02:51:37.897844Z","iopub.status.idle":"2024-06-19T02:51:37.927439Z","shell.execute_reply.started":"2024-06-19T02:51:37.897809Z","shell.execute_reply":"2024-06-19T02:51:37.926571Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"   META_close_mean  META_close_std  META_width_mean  META_width_std  \\\n0       484.822863       15.746056         4.169157        3.165505   \n\n   META_rsi_mean  META_rsi_std  META_roc_mean  META_roc_std  META_volume_mean  \\\n0      50.893476     17.682784       0.051772      0.652936     117441.459096   \n\n   META_volume_std  ...  GOOG_rsi_mean  GOOG_rsi_std  GOOG_roc_mean  \\\n0    119394.564532  ...      49.778738     17.452753      -0.014317   \n\n   GOOG_roc_std  GOOG_volume_mean  GOOG_volume_std  GOOG_diff_mean  \\\n0      0.487646     151418.393162    180722.975073       -0.001228   \n\n   GOOG_diff_std  GOOG_percent_change_close_mean  \\\n0       0.262529                       -0.000582   \n\n   GOOG_percent_change_close_std  \n0                       0.148248  \n\n[1 rows x 70 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>META_close_mean</th>\n      <th>META_close_std</th>\n      <th>META_width_mean</th>\n      <th>META_width_std</th>\n      <th>META_rsi_mean</th>\n      <th>META_rsi_std</th>\n      <th>META_roc_mean</th>\n      <th>META_roc_std</th>\n      <th>META_volume_mean</th>\n      <th>META_volume_std</th>\n      <th>...</th>\n      <th>GOOG_rsi_mean</th>\n      <th>GOOG_rsi_std</th>\n      <th>GOOG_roc_mean</th>\n      <th>GOOG_roc_std</th>\n      <th>GOOG_volume_mean</th>\n      <th>GOOG_volume_std</th>\n      <th>GOOG_diff_mean</th>\n      <th>GOOG_diff_std</th>\n      <th>GOOG_percent_change_close_mean</th>\n      <th>GOOG_percent_change_close_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>484.822863</td>\n      <td>15.746056</td>\n      <td>4.169157</td>\n      <td>3.165505</td>\n      <td>50.893476</td>\n      <td>17.682784</td>\n      <td>0.051772</td>\n      <td>0.652936</td>\n      <td>117441.459096</td>\n      <td>119394.564532</td>\n      <td>...</td>\n      <td>49.778738</td>\n      <td>17.452753</td>\n      <td>-0.014317</td>\n      <td>0.487646</td>\n      <td>151418.393162</td>\n      <td>180722.975073</td>\n      <td>-0.001228</td>\n      <td>0.262529</td>\n      <td>-0.000582</td>\n      <td>0.148248</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 70 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Concatenate all ticker DataFrames\ndf = pd.concat(ticker_data_frames, axis=1)\ndf.replace([np.inf, -np.inf], np.nan, inplace=True)\ndf.dropna(inplace=True)\ndf.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"id":"qekxvEZk7woI","outputId":"a16cbaae-d8f0-4f6f-db1c-c7ddde8b0302","execution":{"iopub.status.busy":"2024-06-19T02:51:40.121676Z","iopub.execute_input":"2024-06-19T02:51:40.122379Z","iopub.status.idle":"2024-06-19T02:51:40.152827Z","shell.execute_reply.started":"2024-06-19T02:51:40.122343Z","shell.execute_reply":"2024-06-19T02:51:40.151940Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                           META_close  META_width  META_rsi  META_roc  \\\nDatetime                                                                \n2024-05-20 10:40:00-04:00   -0.827056   -0.243538 -0.185691 -0.264102   \n2024-05-20 10:45:00-04:00   -0.851823   -0.250691 -0.075215 -0.111774   \n2024-05-20 10:50:00-04:00   -0.856149   -0.236992  0.061301  0.061201   \n2024-05-20 10:55:00-04:00   -0.881990   -0.357632  0.358524  0.388816   \n2024-05-20 11:00:00-04:00   -0.900084   -0.364608 -0.298463 -0.316446   \n\n                           META_volume  META_diff  META_percent_change_close  \\\nDatetime                                                                       \n2024-05-20 10:40:00-04:00     0.500186   0.575418                   0.590837   \n2024-05-20 10:45:00-04:00    -0.242469  -0.505126                  -0.518513   \n2024-05-20 10:50:00-04:00    -0.362273  -0.105347                  -0.108379   \n2024-05-20 10:55:00-04:00    -0.416815  -0.526125                  -0.540564   \n2024-05-20 11:00:00-04:00    -0.339224  -0.374620                  -0.385271   \n\n                           AAPL_close  AAPL_width  AAPL_rsi  ...  AMZN_volume  \\\nDatetime                                                     ...                \n2024-05-20 10:40:00-04:00   -0.708001    0.558623  1.850961  ...    -0.378210   \n2024-05-20 10:45:00-04:00   -0.702106    0.409069  1.737899  ...    -0.498962   \n2024-05-20 10:50:00-04:00   -0.716737    0.167665  1.481250  ...    -0.429798   \n2024-05-20 10:55:00-04:00   -0.710574   -0.146582  1.460356  ...    -0.041516   \n2024-05-20 11:00:00-04:00   -0.703382   -0.385915  1.251490  ...    -0.452868   \n\n                           AMZN_diff  AMZN_percent_change_close  GOOG_close  \\\nDatetime                                                                      \n2024-05-20 10:40:00-04:00  -0.155313                  -0.153601    1.296152   \n2024-05-20 10:45:00-04:00   0.984683                   0.968969    1.206814   \n2024-05-20 10:50:00-04:00   0.093272                   0.091041    1.160594   \n2024-05-20 10:55:00-04:00  -1.238880                  -1.218858    1.025605   \n2024-05-20 11:00:00-04:00   0.714766                   0.703349    0.996713   \n\n                           GOOG_width  GOOG_rsi  GOOG_roc  GOOG_volume  \\\nDatetime                                                                 \n2024-05-20 10:40:00-04:00   -0.293427  0.706943  0.787445     0.161145   \n2024-05-20 10:45:00-04:00   -0.348898  0.127098  0.143962     0.242269   \n2024-05-20 10:50:00-04:00   -0.233238 -0.448752 -0.379921     0.409652   \n2024-05-20 10:55:00-04:00   -0.012514 -0.519210 -0.457180    -0.229326   \n2024-05-20 11:00:00-04:00    0.178696 -1.252204 -0.958768    -0.119417   \n\n                           GOOG_diff  GOOG_percent_change_close  \nDatetime                                                         \n2024-05-20 10:40:00-04:00   0.358874                   0.354088  \n2024-05-20 10:45:00-04:00  -0.643211                  -0.636254  \n2024-05-20 10:50:00-04:00  -0.330514                  -0.327592  \n2024-05-20 10:55:00-04:00  -0.974276                  -0.964773  \n2024-05-20 11:00:00-04:00  -0.204854                  -0.203709  \n\n[5 rows x 35 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>META_close</th>\n      <th>META_width</th>\n      <th>META_rsi</th>\n      <th>META_roc</th>\n      <th>META_volume</th>\n      <th>META_diff</th>\n      <th>META_percent_change_close</th>\n      <th>AAPL_close</th>\n      <th>AAPL_width</th>\n      <th>AAPL_rsi</th>\n      <th>...</th>\n      <th>AMZN_volume</th>\n      <th>AMZN_diff</th>\n      <th>AMZN_percent_change_close</th>\n      <th>GOOG_close</th>\n      <th>GOOG_width</th>\n      <th>GOOG_rsi</th>\n      <th>GOOG_roc</th>\n      <th>GOOG_volume</th>\n      <th>GOOG_diff</th>\n      <th>GOOG_percent_change_close</th>\n    </tr>\n    <tr>\n      <th>Datetime</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2024-05-20 10:40:00-04:00</th>\n      <td>-0.827056</td>\n      <td>-0.243538</td>\n      <td>-0.185691</td>\n      <td>-0.264102</td>\n      <td>0.500186</td>\n      <td>0.575418</td>\n      <td>0.590837</td>\n      <td>-0.708001</td>\n      <td>0.558623</td>\n      <td>1.850961</td>\n      <td>...</td>\n      <td>-0.378210</td>\n      <td>-0.155313</td>\n      <td>-0.153601</td>\n      <td>1.296152</td>\n      <td>-0.293427</td>\n      <td>0.706943</td>\n      <td>0.787445</td>\n      <td>0.161145</td>\n      <td>0.358874</td>\n      <td>0.354088</td>\n    </tr>\n    <tr>\n      <th>2024-05-20 10:45:00-04:00</th>\n      <td>-0.851823</td>\n      <td>-0.250691</td>\n      <td>-0.075215</td>\n      <td>-0.111774</td>\n      <td>-0.242469</td>\n      <td>-0.505126</td>\n      <td>-0.518513</td>\n      <td>-0.702106</td>\n      <td>0.409069</td>\n      <td>1.737899</td>\n      <td>...</td>\n      <td>-0.498962</td>\n      <td>0.984683</td>\n      <td>0.968969</td>\n      <td>1.206814</td>\n      <td>-0.348898</td>\n      <td>0.127098</td>\n      <td>0.143962</td>\n      <td>0.242269</td>\n      <td>-0.643211</td>\n      <td>-0.636254</td>\n    </tr>\n    <tr>\n      <th>2024-05-20 10:50:00-04:00</th>\n      <td>-0.856149</td>\n      <td>-0.236992</td>\n      <td>0.061301</td>\n      <td>0.061201</td>\n      <td>-0.362273</td>\n      <td>-0.105347</td>\n      <td>-0.108379</td>\n      <td>-0.716737</td>\n      <td>0.167665</td>\n      <td>1.481250</td>\n      <td>...</td>\n      <td>-0.429798</td>\n      <td>0.093272</td>\n      <td>0.091041</td>\n      <td>1.160594</td>\n      <td>-0.233238</td>\n      <td>-0.448752</td>\n      <td>-0.379921</td>\n      <td>0.409652</td>\n      <td>-0.330514</td>\n      <td>-0.327592</td>\n    </tr>\n    <tr>\n      <th>2024-05-20 10:55:00-04:00</th>\n      <td>-0.881990</td>\n      <td>-0.357632</td>\n      <td>0.358524</td>\n      <td>0.388816</td>\n      <td>-0.416815</td>\n      <td>-0.526125</td>\n      <td>-0.540564</td>\n      <td>-0.710574</td>\n      <td>-0.146582</td>\n      <td>1.460356</td>\n      <td>...</td>\n      <td>-0.041516</td>\n      <td>-1.238880</td>\n      <td>-1.218858</td>\n      <td>1.025605</td>\n      <td>-0.012514</td>\n      <td>-0.519210</td>\n      <td>-0.457180</td>\n      <td>-0.229326</td>\n      <td>-0.974276</td>\n      <td>-0.964773</td>\n    </tr>\n    <tr>\n      <th>2024-05-20 11:00:00-04:00</th>\n      <td>-0.900084</td>\n      <td>-0.364608</td>\n      <td>-0.298463</td>\n      <td>-0.316446</td>\n      <td>-0.339224</td>\n      <td>-0.374620</td>\n      <td>-0.385271</td>\n      <td>-0.703382</td>\n      <td>-0.385915</td>\n      <td>1.251490</td>\n      <td>...</td>\n      <td>-0.452868</td>\n      <td>0.714766</td>\n      <td>0.703349</td>\n      <td>0.996713</td>\n      <td>0.178696</td>\n      <td>-1.252204</td>\n      <td>-0.958768</td>\n      <td>-0.119417</td>\n      <td>-0.204854</td>\n      <td>-0.203709</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 35 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Shift the df data to create labels\nlabels = df.shift(-1)\n\n# Drop the last row in both percent_change_data and labels as it won't have a corresponding label\ndf = df.iloc[:-1]\nlabels = labels.iloc[:-1]","metadata":{"id":"l_DDzDQp8Hju","execution":{"iopub.status.busy":"2024-06-19T02:51:41.499774Z","iopub.execute_input":"2024-06-19T02:51:41.500441Z","iopub.status.idle":"2024-06-19T02:51:41.505513Z","shell.execute_reply.started":"2024-06-19T02:51:41.500407Z","shell.execute_reply":"2024-06-19T02:51:41.504601Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Sequence len = 24 means that we have 2 hours of 5 min data\nSEQUENCE_LEN = 24\n\n# Function to create X-day sequences for each ticker\ndef create_sequences(data, labels, mean, std, sequence_length=SEQUENCE_LEN):\n    sequences = []\n    lab = []\n    data_size = len(data)\n\n    # + 12 because we want to predict the next hour\n    for i in range(data_size - (sequence_length + 13)):\n      if i == 0:\n        continue\n\n      sequences.append(data[i:i + sequence_length])\n      lab.append([labels[i-1], labels[i + 12], mean[0], std[0]])\n\n    for i in range(0, len(lab)):\n      last_price_data = sequences[i][-1][0]\n      last_price_label = lab[i][0]\n\n      if not last_price_data == last_price_label:\n        print(f\"ERROR : {last_price_data=} and {last_price_label=} are not equal\")\n\n    return np.array(sequences), np.array(lab)","metadata":{"id":"k0Jdnzly9FQ3","execution":{"iopub.status.busy":"2024-06-19T02:51:42.637872Z","iopub.execute_input":"2024-06-19T02:51:42.638698Z","iopub.status.idle":"2024-06-19T02:51:42.646188Z","shell.execute_reply.started":"2024-06-19T02:51:42.638663Z","shell.execute_reply":"2024-06-19T02:51:42.645194Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"sequences_dict = {}\nsequence_labels = {}\nfor ticker in tickers:\n\n    # Extract close and volume data for the ticker\n    close = df[ticker+'_close'].values\n    width = df[ticker+'_width'].values\n    rsi = df[ticker+'_rsi'].values\n    roc = df[ticker+'_roc'].values\n    volume = df[ticker+'_volume'].values\n    diff = df[ticker+'_diff'].values\n    pct_change = df[ticker+'_percent_change_close'].values\n\n    # Combine close and volume data\n    ticker_data = np.column_stack((close,\n                                   width,\n                                   rsi,\n                                   roc,\n                                   volume,\n                                   diff,\n                                   pct_change))\n    print(ticker_data.shape)\n\n    # Generate sequences\n    attribute = ticker+\"_close\"\n    print(labels[attribute].values[SEQUENCE_LEN-1:])\n    print(labels[attribute].values[SEQUENCE_LEN-1:].shape)\n    ticker_sequences, lab = create_sequences(ticker_data,\n                                             labels[attribute].values[SEQUENCE_LEN-1:],\n                                             stats[attribute+\"_mean\"].values,\n                                             stats[attribute+\"_std\"].values)\n\n    sequences_dict[ticker] = ticker_sequences\n    print(sequences_dict[ticker].shape)\n    sequence_labels[ticker] = lab\n    print(sequence_labels[ticker].shape)","metadata":{"id":"y4Mh2yj79Ud9","outputId":"33b0013f-6d49-4676-b5fb-cd3eaf79d422","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-19T02:51:43.153858Z","iopub.execute_input":"2024-06-19T02:51:43.154688Z","iopub.status.idle":"2024-06-19T02:51:43.202884Z","shell.execute_reply.started":"2024-06-19T02:51:43.154653Z","shell.execute_reply":"2024-06-19T02:51:43.202076Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"(1623, 7)\n[-0.81054367 -0.86770046 -0.83594647 ...  0.887025    0.87019445\n  0.94545124]\n(1600,)\n(1585, 24, 7)\n(1585, 4)\n(1623, 7)\n[-0.72086281 -0.71777613 -0.71022427 ...  1.63332112  1.65597825\n  1.64568983]\n(1600,)\n(1585, 24, 7)\n(1585, 4)\n(1623, 7)\n[-0.24801027 -0.27038381 -0.2556279  ...  1.70930456  1.76451936\n  1.73120164]\n(1600,)\n(1585, 24, 7)\n(1585, 4)\n(1623, 7)\n[0.7031386  0.66965901 0.71979673 ... 0.00406851 0.14287099 0.17130312]\n(1600,)\n(1585, 24, 7)\n(1585, 4)\n(1623, 7)\n[ 0.6683335   0.6605594   0.72359372 ... -0.42668445 -0.10628737\n -0.10628737]\n(1600,)\n(1585, 24, 7)\n(1585, 4)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Combine data and labels from all tickers\nall_sequences = []\nall_labels = []\n\nfor ticker in tickers:\n    all_sequences.extend(sequences_dict[ticker])\n    all_labels.extend(sequence_labels[ticker])\n\n# Convert to numpy arrays\nall_sequences = np.array(all_sequences)\nall_labels = np.array(all_labels)\nprint(all_sequences.shape)","metadata":{"id":"-oXY-sXP-fnZ","outputId":"47281af2-6054-422f-ebf2-2e28882513f7","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-19T02:51:43.513870Z","iopub.execute_input":"2024-06-19T02:51:43.514244Z","iopub.status.idle":"2024-06-19T02:51:43.539741Z","shell.execute_reply.started":"2024-06-19T02:51:43.514214Z","shell.execute_reply":"2024-06-19T02:51:43.538856Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"(7925, 24, 7)\n","output_type":"stream"}]},{"cell_type":"code","source":"np.random.seed(42)\nshuffled_indices = np.random.permutation(len(all_sequences))\nall_sequences = all_sequences[shuffled_indices]\nall_labels = all_labels[shuffled_indices]\n\ntrain_size = int(len(all_sequences) * 0.9)\n\n# Split sequences\ntrain_sequences = all_sequences[:train_size]\ntrain_labels    = all_labels[:train_size]\n\nother_sequences = all_sequences[train_size:]\nother_labels    = all_labels[train_size:]\n\nshuffled_indices = np.random.permutation(len(other_sequences))\nother_sequences = other_sequences[shuffled_indices]\nother_labels = other_labels[shuffled_indices]\n\nval_size = int(len(other_sequences) * 0.5)\n\nvalidation_sequences = other_sequences[:val_size]\nvalidation_labels = other_labels[:val_size]\n\ntest_sequences = other_sequences[val_size:]\ntest_labels = other_labels[val_size:]","metadata":{"id":"8QY42PaV-kPG","execution":{"iopub.status.busy":"2024-06-19T02:51:44.206841Z","iopub.execute_input":"2024-06-19T02:51:44.207446Z","iopub.status.idle":"2024-06-19T02:51:44.221855Z","shell.execute_reply.started":"2024-06-19T02:51:44.207414Z","shell.execute_reply":"2024-06-19T02:51:44.220962Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n    # Attention and Normalization\n    x = LayerNormalization(epsilon=1e-6)(inputs)\n    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n    x = Add()([x, inputs])\n\n    # Feed Forward Part\n    y = LayerNormalization(epsilon=1e-6)(x)\n    y = Dense(ff_dim, activation=\"relu\")(y)\n    y = Dropout(dropout)(y)\n    y = Dense(inputs.shape[-1])(y)\n    return Add()([y, x])\n\ndef build_transformer_model(input_shape, head_size, num_heads, ff_dim, num_layers, dropout=0):\n    inputs = Input(shape=input_shape)\n    x = inputs\n\n    # Create multiple layers of the Transformer block\n    for _ in range(num_layers):\n        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n\n    # Final part of the model\n    x = GlobalAveragePooling1D()(x)\n    x = LayerNormalization(epsilon=1e-6)(x)\n    outputs = Dense(1, activation=\"linear\")(x)\n\n    # Compile model\n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n\n# Model parameters\ninput_shape = train_sequences.shape[1:]\nhead_size = 256\nnum_heads = 16\nff_dim = 1024\nnum_layers = 12\ndropout = 0.20\n\n# Build the model\nmodel = build_transformer_model(input_shape, head_size, num_heads, ff_dim, num_layers, dropout)\nmodel.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBKt-Fhj-p3w","outputId":"9c54a943-3cdb-4dc6-aa22-361350f08cc7","execution":{"iopub.status.busy":"2024-06-19T02:51:44.937749Z","iopub.execute_input":"2024-06-19T02:51:44.938599Z","iopub.status.idle":"2024-06-19T02:51:46.438986Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │    \u001b[38;5;34m126,983\u001b[0m │ layer_normalizat… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n│                     │                   │            │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │      \u001b[38;5;34m8,192\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │      \u001b[38;5;34m7,175\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│                     │                   │            │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │    \u001b[38;5;34m126,983\u001b[0m │ layer_normalizat… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n│                     │                   │            │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │      \u001b[38;5;34m8,192\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │      \u001b[38;5;34m7,175\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│                     │                   │            │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │    \u001b[38;5;34m126,983\u001b[0m │ layer_normalizat… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n│                     │                   │            │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │      \u001b[38;5;34m8,192\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │      \u001b[38;5;34m7,175\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│                     │                   │            │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │    \u001b[38;5;34m126,983\u001b[0m │ layer_normalizat… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n│                     │                   │            │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │      \u001b[38;5;34m8,192\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │      \u001b[38;5;34m7,175\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_7 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│                     │                   │            │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │    \u001b[38;5;34m126,983\u001b[0m │ layer_normalizat… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_8 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n│                     │                   │            │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │      \u001b[38;5;34m8,192\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │      \u001b[38;5;34m7,175\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_9 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│                     │                   │            │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │    \u001b[38;5;34m126,983\u001b[0m │ layer_normalizat… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_10 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n│                     │                   │            │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │      \u001b[38;5;34m8,192\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │      \u001b[38;5;34m7,175\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_11 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                     │                   │            │ add_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │    \u001b[38;5;34m126,983\u001b[0m │ layer_normalizat… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_12 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n│                     │                   │            │ add_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │      \u001b[38;5;34m8,192\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │      \u001b[38;5;34m7,175\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_13 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                     │                   │            │ add_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │    \u001b[38;5;34m126,983\u001b[0m │ layer_normalizat… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_14 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n│                     │                   │            │ add_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_14 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │      \u001b[38;5;34m8,192\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_15 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │      \u001b[38;5;34m7,175\u001b[0m │ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_15 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                     │                   │            │ add_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │    \u001b[38;5;34m126,983\u001b[0m │ layer_normalizat… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_16 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n│                     │                   │            │ add_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_16 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │      \u001b[38;5;34m8,192\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_17 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │      \u001b[38;5;34m7,175\u001b[0m │ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_17 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                     │                   │            │ add_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │    \u001b[38;5;34m126,983\u001b[0m │ layer_normalizat… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_18 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n│                     │                   │            │ add_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_18 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │      \u001b[38;5;34m8,192\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_19 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │      \u001b[38;5;34m7,175\u001b[0m │ dropout_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_19 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                     │                   │            │ add_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │    \u001b[38;5;34m126,983\u001b[0m │ layer_normalizat… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_20 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n│                     │                   │            │ add_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_20 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │      \u001b[38;5;34m8,192\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_21 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │      \u001b[38;5;34m7,175\u001b[0m │ dropout_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_21 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                     │                   │            │ add_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │    \u001b[38;5;34m126,983\u001b[0m │ layer_normalizat… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_22 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n│                     │                   │            │ add_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │         \u001b[38;5;34m14\u001b[0m │ add_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_22 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │      \u001b[38;5;34m8,192\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_23 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │      \u001b[38;5;34m7,175\u001b[0m │ dropout_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_23 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                     │                   │            │ add_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ add_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │         \u001b[38;5;34m14\u001b[0m │ global_average_p… │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_24 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m8\u001b[0m │ layer_normalizat… │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">126,983</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n│                     │                   │            │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,175</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│                     │                   │            │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">126,983</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n│                     │                   │            │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,175</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│                     │                   │            │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">126,983</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n│                     │                   │            │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,175</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│                     │                   │            │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">126,983</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n│                     │                   │            │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,175</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│                     │                   │            │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">126,983</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n│                     │                   │            │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,175</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│                     │                   │            │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">126,983</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n│                     │                   │            │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,175</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                     │                   │            │ add_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">126,983</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n│                     │                   │            │ add_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,175</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                     │                   │            │ add_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">126,983</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n│                     │                   │            │ add_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,175</span> │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                     │                   │            │ add_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">126,983</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n│                     │                   │            │ add_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,175</span> │ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                     │                   │            │ add_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">126,983</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n│                     │                   │            │ add_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,175</span> │ dropout_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                     │                   │            │ add_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">126,983</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n│                     │                   │            │ add_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,175</span> │ dropout_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                     │                   │            │ add_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">126,983</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n│                     │                   │            │ add_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ add_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,175</span> │ dropout_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                     │                   │            │ add_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │ global_average_p… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ layer_normalizat… │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,708,558\u001b[0m (6.52 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,708,558</span> (6.52 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"def custom_mae_loss(y_true, y_pred):\n    y_true_next = tf.cast(y_true[:, 1], tf.float64)\n    y_pred_next = tf.cast(y_pred[:, 0], tf.float64)\n    abs_error = tf.abs(y_true_next - y_pred_next)\n\n    return tf.reduce_mean(abs_error)\n\ndef dir_acc(y_true, y_pred):\n    mean, std = tf.cast(y_true[:, 2], tf.float64), tf.cast(y_true[:, 3], tf.float64)\n\n    y_true_prev = (tf.cast(y_true[:, 0], tf.float64) * std) + mean\n    y_true_next = (tf.cast(y_true[:, 1], tf.float64) * std) + mean\n    y_pred_next = (tf.cast(y_pred[:, 0], tf.float64) * std) + mean\n\n    true_change = y_true_next - y_true_prev\n    pred_change = y_pred_next - y_true_prev\n\n    correct_direction = tf.equal(tf.sign(true_change), tf.sign(pred_change))\n\n    return tf.reduce_mean(tf.cast(correct_direction, tf.float64))","metadata":{"id":"bWMOzku9-vpv","execution":{"iopub.status.busy":"2024-06-19T02:52:12.261796Z","iopub.execute_input":"2024-06-19T02:52:12.262691Z","iopub.status.idle":"2024-06-19T02:52:12.270805Z","shell.execute_reply.started":"2024-06-19T02:52:12.262654Z","shell.execute_reply":"2024-06-19T02:52:12.269858Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Compile the model\noptimizer = tf.keras.optimizers.Adam()\nmodel.compile(optimizer=optimizer, loss=custom_mae_loss, metrics=[dir_acc])","metadata":{"id":"CQ20qXHdABEa","execution":{"iopub.status.busy":"2024-06-19T02:52:15.024924Z","iopub.execute_input":"2024-06-19T02:52:15.025552Z","iopub.status.idle":"2024-06-19T02:52:15.041597Z","shell.execute_reply.started":"2024-06-19T02:52:15.025522Z","shell.execute_reply":"2024-06-19T02:52:15.040774Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Define a callback to save the best model\ncheckpoint_callback_train = ModelCheckpoint(\n    \"transformer_train_model.keras\",  # Filepath to save the best model\n    monitor=\"dir_acc\",  #\"loss\",  # Metric to monitor\n    save_best_only=True,  # Save only the best model\n    mode=\"max\",  # Minimize the monitored metric\n    verbose=1,  # Display progress\n)\n\n# Define a callback to save the best model\ncheckpoint_callback_val = ModelCheckpoint(\n    \"transformer_val_model.keras\",  # Filepath to save the best model\n    monitor=\"val_dir_acc\", #\"val_loss\",  # Metric to monitor\n    save_best_only=True,  # Save only the best model\n    mode=\"max\",  # Minimize the monitored metric\n    verbose=1,  # Display progress\n)\n\ndef get_lr_callback(batch_size=16, mode='cos', epochs=500, plot=False):\n    lr_start, lr_max, lr_min = 0.0001, 0.005, 0.00001  # Adjust learning rate boundaries\n    lr_ramp_ep = int(0.30 * epochs)  # 30% of epochs for warm-up\n    lr_sus_ep = max(0, int(0.10 * epochs) - lr_ramp_ep)  # Optional sustain phase, adjust as needed\n\n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:  # Warm-up phase\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n        elif epoch < lr_ramp_ep + lr_sus_ep:  # Sustain phase at max learning rate\n            lr = lr_max\n        elif mode == 'cos':\n            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep, epoch - lr_ramp_ep - lr_sus_ep\n            phase = math.pi * decay_epoch_index / decay_total_epochs\n            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n        else:\n            lr = lr_min  # Default to minimum learning rate if mode is not recognized\n\n        return lr\n\n    if plot:  # Plot learning rate curve if plot is True\n        plt.figure(figsize=(10, 5))\n        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n        plt.xlabel('Epoch')\n        plt.ylabel('Learning Rate')\n        plt.title('Learning Rate Scheduler')\n        plt.show()\n\n    return tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)","metadata":{"id":"1kVujFs0BQu8","execution":{"iopub.status.busy":"2024-06-19T02:52:19.203753Z","iopub.execute_input":"2024-06-19T02:52:19.204114Z","iopub.status.idle":"2024-06-19T02:52:19.215693Z","shell.execute_reply.started":"2024-06-19T02:52:19.204085Z","shell.execute_reply":"2024-06-19T02:52:19.214677Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64\nEPOCHS = 100\nmodel.fit(train_sequences, train_labels,\n          validation_data=(validation_sequences, validation_labels),\n          epochs=EPOCHS,\n          batch_size=BATCH_SIZE,\n          shuffle=True,\n          callbacks=[checkpoint_callback_train, checkpoint_callback_val, get_lr_callback(batch_size=BATCH_SIZE, epochs=EPOCHS)])","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"4Mv3B5gvBeR-","outputId":"b8f17f5d-f238-4591-e851-69102fb29892","execution":{"iopub.status.busy":"2024-06-19T02:52:20.535945Z","iopub.execute_input":"2024-06-19T02:52:20.536323Z","iopub.status.idle":"2024-06-19T03:22:40.643003Z","shell.execute_reply.started":"2024-06-19T02:52:20.536294Z","shell.execute_reply":"2024-06-19T03:22:40.642156Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"\nEpoch 1: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1718765623.837030     164 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1718765623.903553     164 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622ms/step - dir_acc: 0.5120 - loss: 0.4427","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1718765692.942510     162 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1718765698.844594     163 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: dir_acc improved from -inf to 0.51401, saving model to transformer_train_model.keras\n\nEpoch 1: val_dir_acc improved from -inf to 0.49330, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 724ms/step - dir_acc: 0.5120 - loss: 0.4417 - val_dir_acc: 0.4933 - val_loss: 0.2891 - learning_rate: 1.0000e-04\n\nEpoch 2: LearningRateScheduler setting learning rate to 0.00026333333333333336.\nEpoch 2/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.5280 - loss: 0.3035\nEpoch 2: dir_acc improved from 0.51401 to 0.52386, saving model to transformer_train_model.keras\n\nEpoch 2: val_dir_acc did not improve from 0.49330\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 150ms/step - dir_acc: 0.5280 - loss: 0.3035 - val_dir_acc: 0.4598 - val_loss: 0.2965 - learning_rate: 2.6333e-04\n\nEpoch 3: LearningRateScheduler setting learning rate to 0.00042666666666666667.\nEpoch 3/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.5195 - loss: 0.2796\nEpoch 3: dir_acc did not improve from 0.52386\n\nEpoch 3: val_dir_acc improved from 0.49330 to 0.53646, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.5195 - loss: 0.2796 - val_dir_acc: 0.5365 - val_loss: 0.2700 - learning_rate: 4.2667e-04\n\nEpoch 4: LearningRateScheduler setting learning rate to 0.00059.\nEpoch 4/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.5144 - loss: 0.2881\nEpoch 4: dir_acc improved from 0.52386 to 0.52435, saving model to transformer_train_model.keras\n\nEpoch 4: val_dir_acc did not improve from 0.53646\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.5145 - loss: 0.2881 - val_dir_acc: 0.5231 - val_loss: 0.2800 - learning_rate: 5.9000e-04\n\nEpoch 5: LearningRateScheduler setting learning rate to 0.0007533333333333334.\nEpoch 5/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.5233 - loss: 0.2696\nEpoch 5: dir_acc improved from 0.52435 to 0.53559, saving model to transformer_train_model.keras\n\nEpoch 5: val_dir_acc did not improve from 0.53646\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.5234 - loss: 0.2696 - val_dir_acc: 0.5193 - val_loss: 0.2644 - learning_rate: 7.5333e-04\n\nEpoch 6: LearningRateScheduler setting learning rate to 0.0009166666666666668.\nEpoch 6/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.5348 - loss: 0.2596\nEpoch 6: dir_acc improved from 0.53559 to 0.53888, saving model to transformer_train_model.keras\n\nEpoch 6: val_dir_acc did not improve from 0.53646\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 150ms/step - dir_acc: 0.5349 - loss: 0.2597 - val_dir_acc: 0.5320 - val_loss: 0.2391 - learning_rate: 9.1667e-04\n\nEpoch 7: LearningRateScheduler setting learning rate to 0.00108.\nEpoch 7/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.5501 - loss: 0.2531\nEpoch 7: dir_acc improved from 0.53888 to 0.55142, saving model to transformer_train_model.keras\n\nEpoch 7: val_dir_acc improved from 0.53646 to 0.54315, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 153ms/step - dir_acc: 0.5501 - loss: 0.2531 - val_dir_acc: 0.5432 - val_loss: 0.2813 - learning_rate: 0.0011\n\nEpoch 8: LearningRateScheduler setting learning rate to 0.0012433333333333335.\nEpoch 8/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.5601 - loss: 0.2454\nEpoch 8: dir_acc improved from 0.55142 to 0.56348, saving model to transformer_train_model.keras\n\nEpoch 8: val_dir_acc improved from 0.54315 to 0.56622, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 154ms/step - dir_acc: 0.5601 - loss: 0.2453 - val_dir_acc: 0.5662 - val_loss: 0.2402 - learning_rate: 0.0012\n\nEpoch 9: LearningRateScheduler setting learning rate to 0.0014066666666666667.\nEpoch 9/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.5768 - loss: 0.2393\nEpoch 9: dir_acc improved from 0.56348 to 0.57097, saving model to transformer_train_model.keras\n\nEpoch 9: val_dir_acc did not improve from 0.56622\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.5767 - loss: 0.2394 - val_dir_acc: 0.5506 - val_loss: 0.2172 - learning_rate: 0.0014\n\nEpoch 10: LearningRateScheduler setting learning rate to 0.00157.\nEpoch 10/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.5738 - loss: 0.2224\nEpoch 10: dir_acc improved from 0.57097 to 0.57382, saving model to transformer_train_model.keras\n\nEpoch 10: val_dir_acc did not improve from 0.56622\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.5738 - loss: 0.2225 - val_dir_acc: 0.5573 - val_loss: 0.2307 - learning_rate: 0.0016\n\nEpoch 11: LearningRateScheduler setting learning rate to 0.0017333333333333335.\nEpoch 11/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.5647 - loss: 0.2300\nEpoch 11: dir_acc improved from 0.57382 to 0.58281, saving model to transformer_train_model.keras\n\nEpoch 11: val_dir_acc improved from 0.56622 to 0.58185, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 153ms/step - dir_acc: 0.5648 - loss: 0.2299 - val_dir_acc: 0.5818 - val_loss: 0.2499 - learning_rate: 0.0017\n\nEpoch 12: LearningRateScheduler setting learning rate to 0.0018966666666666667.\nEpoch 12/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.5849 - loss: 0.2284\nEpoch 12: dir_acc improved from 0.58281 to 0.58747, saving model to transformer_train_model.keras\n\nEpoch 12: val_dir_acc did not improve from 0.58185\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.5849 - loss: 0.2284 - val_dir_acc: 0.5499 - val_loss: 0.2151 - learning_rate: 0.0019\n\nEpoch 13: LearningRateScheduler setting learning rate to 0.0020599999999999998.\nEpoch 13/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.5953 - loss: 0.2109\nEpoch 13: dir_acc improved from 0.58747 to 0.60118, saving model to transformer_train_model.keras\n\nEpoch 13: val_dir_acc did not improve from 0.58185\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.5953 - loss: 0.2110 - val_dir_acc: 0.5677 - val_loss: 0.2351 - learning_rate: 0.0021\n\nEpoch 14: LearningRateScheduler setting learning rate to 0.0022233333333333332.\nEpoch 14/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.5963 - loss: 0.2377\nEpoch 14: dir_acc did not improve from 0.60118\n\nEpoch 14: val_dir_acc did not improve from 0.58185\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.5963 - loss: 0.2375 - val_dir_acc: 0.5729 - val_loss: 0.2201 - learning_rate: 0.0022\n\nEpoch 15: LearningRateScheduler setting learning rate to 0.0023866666666666667.\nEpoch 15/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.6147 - loss: 0.2096\nEpoch 15: dir_acc improved from 0.60118 to 0.60561, saving model to transformer_train_model.keras\n\nEpoch 15: val_dir_acc did not improve from 0.58185\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 153ms/step - dir_acc: 0.6147 - loss: 0.2096 - val_dir_acc: 0.5714 - val_loss: 0.2008 - learning_rate: 0.0024\n\nEpoch 16: LearningRateScheduler setting learning rate to 0.0025499999999999997.\nEpoch 16/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6084 - loss: 0.2086\nEpoch 16: dir_acc improved from 0.60561 to 0.61181, saving model to transformer_train_model.keras\n\nEpoch 16: val_dir_acc improved from 0.58185 to 0.58929, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 154ms/step - dir_acc: 0.6085 - loss: 0.2086 - val_dir_acc: 0.5893 - val_loss: 0.2128 - learning_rate: 0.0026\n\nEpoch 17: LearningRateScheduler setting learning rate to 0.0027133333333333332.\nEpoch 17/100\nEpoch 17/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6130 - loss: 0.2210\nEpoch 17: dir_acc did not improve from 0.61181\n\nEpoch 17: val_dir_acc did not improve from 0.58929\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.6129 - loss: 0.2210 - val_dir_acc: 0.5737 - val_loss: 0.2081 - learning_rate: 0.0027\n\nEpoch 18: LearningRateScheduler setting learning rate to 0.0028766666666666667.\nEpoch 18/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6040 - loss: 0.2038\nEpoch 18: dir_acc improved from 0.61181 to 0.61304, saving model to transformer_train_model.keras\n\nEpoch 18: val_dir_acc improved from 0.58929 to 0.61012, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 154ms/step - dir_acc: 0.6041 - loss: 0.2039 - val_dir_acc: 0.6101 - val_loss: 0.2122 - learning_rate: 0.0029\n\nEpoch 19: LearningRateScheduler setting learning rate to 0.0030399999999999997.\nEpoch 19/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.6175 - loss: 0.2069\nEpoch 19: dir_acc improved from 0.61304 to 0.61896, saving model to transformer_train_model.keras\n\nEpoch 19: val_dir_acc did not improve from 0.61012\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - dir_acc: 0.6175 - loss: 0.2068 - val_dir_acc: 0.5908 - val_loss: 0.2249 - learning_rate: 0.0030\n\nEpoch 20: LearningRateScheduler setting learning rate to 0.003203333333333333.\nEpoch 20/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.6235 - loss: 0.2077\nEpoch 20: dir_acc improved from 0.61896 to 0.62309, saving model to transformer_train_model.keras\n\nEpoch 20: val_dir_acc did not improve from 0.61012\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.6235 - loss: 0.2077 - val_dir_acc: 0.6071 - val_loss: 0.1911 - learning_rate: 0.0032\n\nEpoch 21: LearningRateScheduler setting learning rate to 0.0033666666666666667.\nEpoch 21/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6227 - loss: 0.2079\nEpoch 21: dir_acc improved from 0.62309 to 0.62343, saving model to transformer_train_model.keras\n\nEpoch 21: val_dir_acc improved from 0.61012 to 0.61607, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 154ms/step - dir_acc: 0.6228 - loss: 0.2080 - val_dir_acc: 0.6161 - val_loss: 0.1809 - learning_rate: 0.0034\n\nEpoch 22: LearningRateScheduler setting learning rate to 0.0035299999999999997.\nEpoch 22/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6306 - loss: 0.1928\nEpoch 22: dir_acc did not improve from 0.62343\n\nEpoch 22: val_dir_acc did not improve from 0.61607\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 146ms/step - dir_acc: 0.6305 - loss: 0.1929 - val_dir_acc: 0.5275 - val_loss: 0.2579 - learning_rate: 0.0035\n\nEpoch 23: LearningRateScheduler setting learning rate to 0.003693333333333333.\nEpoch 23/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6206 - loss: 0.2058\nEpoch 23: dir_acc improved from 0.62343 to 0.64098, saving model to transformer_train_model.keras\n\nEpoch 23: val_dir_acc did not improve from 0.61607\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 150ms/step - dir_acc: 0.6207 - loss: 0.2057 - val_dir_acc: 0.5595 - val_loss: 0.2534 - learning_rate: 0.0037\n\nEpoch 24: LearningRateScheduler setting learning rate to 0.0038566666666666667.\nEpoch 24/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6219 - loss: 0.1984\nEpoch 24: dir_acc did not improve from 0.64098\n\nEpoch 24: val_dir_acc did not improve from 0.61607\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.6219 - loss: 0.1983 - val_dir_acc: 0.5930 - val_loss: 0.2026 - learning_rate: 0.0039\n\nEpoch 25: LearningRateScheduler setting learning rate to 0.00402.\nEpoch 25/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.6413 - loss: 0.1870\nEpoch 25: dir_acc did not improve from 0.64098\n\nEpoch 25: val_dir_acc improved from 0.61607 to 0.65104, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.6412 - loss: 0.1871 - val_dir_acc: 0.6510 - val_loss: 0.1810 - learning_rate: 0.0040\n\nEpoch 26: LearningRateScheduler setting learning rate to 0.004183333333333334.\nEpoch 26/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6367 - loss: 0.1925\nEpoch 26: dir_acc did not improve from 0.64098\n\nEpoch 26: val_dir_acc improved from 0.65104 to 0.67262, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 150ms/step - dir_acc: 0.6366 - loss: 0.1924 - val_dir_acc: 0.6726 - val_loss: 0.1909 - learning_rate: 0.0042\n\nEpoch 27: LearningRateScheduler setting learning rate to 0.004346666666666667.\nEpoch 27/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6488 - loss: 0.1814\nEpoch 27: dir_acc improved from 0.64098 to 0.64726, saving model to transformer_train_model.keras\n\nEpoch 27: val_dir_acc did not improve from 0.67262\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 150ms/step - dir_acc: 0.6488 - loss: 0.1814 - val_dir_acc: 0.6019 - val_loss: 0.2246 - learning_rate: 0.0043\n\nEpoch 28: LearningRateScheduler setting learning rate to 0.00451.\nEpoch 28/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6419 - loss: 0.1810\nEpoch 28: dir_acc did not improve from 0.64726\n\nEpoch 28: val_dir_acc did not improve from 0.67262\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.6419 - loss: 0.1810 - val_dir_acc: 0.6287 - val_loss: 0.2046 - learning_rate: 0.0045\n\nEpoch 29: LearningRateScheduler setting learning rate to 0.004673333333333334.\nEpoch 29/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6501 - loss: 0.1880\nEpoch 29: dir_acc improved from 0.64726 to 0.65308, saving model to transformer_train_model.keras\n\nEpoch 29: val_dir_acc did not improve from 0.67262\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 150ms/step - dir_acc: 0.6501 - loss: 0.1880 - val_dir_acc: 0.5848 - val_loss: 0.2391 - learning_rate: 0.0047\n\nEpoch 30: LearningRateScheduler setting learning rate to 0.004836666666666667.\nEpoch 30/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6230 - loss: 0.2098\nEpoch 30: dir_acc did not improve from 0.65308\n\nEpoch 30: val_dir_acc did not improve from 0.67262\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.6231 - loss: 0.2097 - val_dir_acc: 0.6101 - val_loss: 0.1924 - learning_rate: 0.0048\n\nEpoch 31: LearningRateScheduler setting learning rate to 0.005.\nEpoch 31/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.6500 - loss: 0.1814\nEpoch 31: dir_acc did not improve from 0.65308\n\nEpoch 31: val_dir_acc did not improve from 0.67262\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.6500 - loss: 0.1813 - val_dir_acc: 0.6302 - val_loss: 0.1824 - learning_rate: 0.0050\n\nEpoch 32: LearningRateScheduler setting learning rate to 0.00499748770102058.\nEpoch 32/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6617 - loss: 0.1745\nEpoch 32: dir_acc improved from 0.65308 to 0.65844, saving model to transformer_train_model.keras\n\nEpoch 32: val_dir_acc did not improve from 0.67262\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 150ms/step - dir_acc: 0.6617 - loss: 0.1745 - val_dir_acc: 0.6153 - val_loss: 0.1942 - learning_rate: 0.0050\n\nEpoch 33: LearningRateScheduler setting learning rate to 0.0049899558635181215.\nEpoch 33/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6640 - loss: 0.1724\nEpoch 33: dir_acc did not improve from 0.65844\n\nEpoch 33: val_dir_acc did not improve from 0.67262\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.6639 - loss: 0.1725 - val_dir_acc: 0.6183 - val_loss: 0.1864 - learning_rate: 0.0050\n\nEpoch 34: LearningRateScheduler setting learning rate to 0.004977419655610997.\nEpoch 34/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.6564 - loss: 0.1730\nEpoch 34: dir_acc did not improve from 0.65844\n\nEpoch 34: val_dir_acc did not improve from 0.67262\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 144ms/step - dir_acc: 0.6564 - loss: 0.1730 - val_dir_acc: 0.6272 - val_loss: 0.1985 - learning_rate: 0.0050\n\nEpoch 35: LearningRateScheduler setting learning rate to 0.004959904323553581.\nEpoch 35/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.6567 - loss: 0.1785\nEpoch 35: dir_acc did not improve from 0.65844\n\nEpoch 35: val_dir_acc did not improve from 0.67262\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 144ms/step - dir_acc: 0.6567 - loss: 0.1785 - val_dir_acc: 0.6339 - val_loss: 0.1790 - learning_rate: 0.0050\n\nEpoch 36: LearningRateScheduler setting learning rate to 0.0049374451408936496.\nEpoch 36/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.6744 - loss: 0.1660\nEpoch 36: dir_acc improved from 0.65844 to 0.66482, saving model to transformer_train_model.keras\n\nEpoch 36: val_dir_acc did not improve from 0.67262\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.6743 - loss: 0.1660 - val_dir_acc: 0.6190 - val_loss: 0.1978 - learning_rate: 0.0049\n\nEpoch 37: LearningRateScheduler setting learning rate to 0.004910087337436154.\nEpoch 37/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.6612 - loss: 0.1785\nEpoch 37: dir_acc did not improve from 0.66482\n\nEpoch 37: val_dir_acc did not improve from 0.67262\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.6612 - loss: 0.1784 - val_dir_acc: 0.6414 - val_loss: 0.1887 - learning_rate: 0.0049\n\nEpoch 38: LearningRateScheduler setting learning rate to 0.004877886008156408.\nEpoch 38/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.6497 - loss: 0.1752\nEpoch 38: dir_acc did not improve from 0.66482\n\nEpoch 38: val_dir_acc did not improve from 0.67262\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.6498 - loss: 0.1751 - val_dir_acc: 0.6235 - val_loss: 0.1614 - learning_rate: 0.0049\n\nEpoch 39: LearningRateScheduler setting learning rate to 0.004840906002246144.\nEpoch 39/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.6776 - loss: 0.1575\nEpoch 39: dir_acc improved from 0.66482 to 0.68208, saving model to transformer_train_model.keras\n\nEpoch 39: val_dir_acc improved from 0.67262 to 0.68229, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 154ms/step - dir_acc: 0.6777 - loss: 0.1576 - val_dir_acc: 0.6823 - val_loss: 0.1709 - learning_rate: 0.0048\n\nEpoch 40: LearningRateScheduler setting learning rate to 0.00479922179251587.\nEpoch 40/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.6682 - loss: 0.1662\nEpoch 40: dir_acc did not improve from 0.68208\n\nEpoch 40: val_dir_acc did not improve from 0.68229\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 144ms/step - dir_acc: 0.6682 - loss: 0.1662 - val_dir_acc: 0.6756 - val_loss: 0.1728 - learning_rate: 0.0048\n\nEpoch 41: LearningRateScheduler setting learning rate to 0.0047529173254165355.\nEpoch 41/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.6773 - loss: 0.1578\nEpoch 41: dir_acc did not improve from 0.68208\n\nEpoch 41: val_dir_acc did not improve from 0.68229\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 144ms/step - dir_acc: 0.6773 - loss: 0.1578 - val_dir_acc: 0.6637 - val_loss: 0.1750 - learning_rate: 0.0048\n\nEpoch 42: LearningRateScheduler setting learning rate to 0.004702085851982562.\nEpoch 42/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6805 - loss: 0.1605\nEpoch 42: dir_acc did not improve from 0.68208\n\nEpoch 42: val_dir_acc did not improve from 0.68229\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.6804 - loss: 0.1605 - val_dir_acc: 0.6473 - val_loss: 0.1631 - learning_rate: 0.0047\n\nEpoch 43: LearningRateScheduler setting learning rate to 0.004646829740036656.\nEpoch 43/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6725 - loss: 0.1619\nEpoch 43: dir_acc did not improve from 0.68208\n\nEpoch 43: val_dir_acc did not improve from 0.68229\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 146ms/step - dir_acc: 0.6725 - loss: 0.1619 - val_dir_acc: 0.6607 - val_loss: 0.1782 - learning_rate: 0.0046\n\nEpoch 44: LearningRateScheduler setting learning rate to 0.00458726026803465.\nEpoch 44/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6830 - loss: 0.1500\nEpoch 44: dir_acc improved from 0.68208 to 0.68232, saving model to transformer_train_model.keras\n\nEpoch 44: val_dir_acc did not improve from 0.68229\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 150ms/step - dir_acc: 0.6830 - loss: 0.1501 - val_dir_acc: 0.6317 - val_loss: 0.1764 - learning_rate: 0.0046\n\nEpoch 45: LearningRateScheduler setting learning rate to 0.004523497400965494.\nEpoch 45/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.6796 - loss: 0.1565\nEpoch 45: dir_acc did not improve from 0.68232\n\nEpoch 45: val_dir_acc did not improve from 0.68229\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.6796 - loss: 0.1565 - val_dir_acc: 0.6622 - val_loss: 0.1582 - learning_rate: 0.0045\n\nEpoch 46: LearningRateScheduler setting learning rate to 0.004455669548757734.\nEpoch 46/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.6852 - loss: 0.1579\nEpoch 46: dir_acc did not improve from 0.68232\n\nEpoch 46: val_dir_acc did not improve from 0.68229\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.6851 - loss: 0.1579 - val_dir_acc: 0.6562 - val_loss: 0.1553 - learning_rate: 0.0045\n\nEpoch 47: LearningRateScheduler setting learning rate to 0.00438391330767901.\nEpoch 47/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.6911 - loss: 0.1493\nEpoch 47: dir_acc improved from 0.68232 to 0.69300, saving model to transformer_train_model.keras\n\nEpoch 47: val_dir_acc did not improve from 0.68229\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 150ms/step - dir_acc: 0.6911 - loss: 0.1493 - val_dir_acc: 0.6399 - val_loss: 0.1621 - learning_rate: 0.0044\n\nEpoch 48: LearningRateScheduler setting learning rate to 0.004308373185249342.\nEpoch 48/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.6915 - loss: 0.1501\nEpoch 48: dir_acc did not improve from 0.69300\n\nEpoch 48: val_dir_acc did not improve from 0.68229\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.6914 - loss: 0.1501 - val_dir_acc: 0.6555 - val_loss: 0.1683 - learning_rate: 0.0043\n\nEpoch 49: LearningRateScheduler setting learning rate to 0.004229201309222228.\nEpoch 49/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.6853 - loss: 0.1537\nEpoch 49: dir_acc did not improve from 0.69300\n\nEpoch 49: val_dir_acc did not improve from 0.68229\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 144ms/step - dir_acc: 0.6854 - loss: 0.1537 - val_dir_acc: 0.6726 - val_loss: 0.1573 - learning_rate: 0.0042\n\nEpoch 50: LearningRateScheduler setting learning rate to 0.0041465571212195825.\nEpoch 50/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7049 - loss: 0.1448\nEpoch 50: dir_acc improved from 0.69300 to 0.70181, saving model to transformer_train_model.keras\n\nEpoch 50: val_dir_acc improved from 0.68229 to 0.70387, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 154ms/step - dir_acc: 0.7048 - loss: 0.1448 - val_dir_acc: 0.7039 - val_loss: 0.1528 - learning_rate: 0.0041\n\nEpoch 51: LearningRateScheduler setting learning rate to 0.0040606070556375405.\nEpoch 51/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7009 - loss: 0.1425\nEpoch 51: dir_acc improved from 0.70181 to 0.70195, saving model to transformer_train_model.keras\n\nEpoch 51: val_dir_acc did not improve from 0.70387\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7009 - loss: 0.1425 - val_dir_acc: 0.6979 - val_loss: 0.1535 - learning_rate: 0.0041\n\nEpoch 52: LearningRateScheduler setting learning rate to 0.00397152420446972.\nEpoch 52/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7038 - loss: 0.1418\nEpoch 52: dir_acc did not improve from 0.70195\n\nEpoch 52: val_dir_acc did not improve from 0.70387\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.7038 - loss: 0.1419 - val_dir_acc: 0.6615 - val_loss: 0.1776 - learning_rate: 0.0040\n\nEpoch 53: LearningRateScheduler setting learning rate to 0.0038794879687229964.\nEpoch 53/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7093 - loss: 0.1501\nEpoch 53: dir_acc improved from 0.70195 to 0.71187, saving model to transformer_train_model.keras\n\nEpoch 53: val_dir_acc did not improve from 0.70387\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7093 - loss: 0.1501 - val_dir_acc: 0.6860 - val_loss: 0.1456 - learning_rate: 0.0039\n\nEpoch 54: LearningRateScheduler setting learning rate to 0.0037846836971277367.\nEpoch 54/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.7014 - loss: 0.1365\nEpoch 54: dir_acc did not improve from 0.71187\n\nEpoch 54: val_dir_acc did not improve from 0.70387\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.7014 - loss: 0.1365 - val_dir_acc: 0.6771 - val_loss: 0.1519 - learning_rate: 0.0038\n\nEpoch 55: LearningRateScheduler setting learning rate to 0.003687302312870132.\nEpoch 55/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7093 - loss: 0.1400\nEpoch 55: dir_acc did not improve from 0.71187\n\nEpoch 55: val_dir_acc improved from 0.70387 to 0.70833, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7093 - loss: 0.1401 - val_dir_acc: 0.7083 - val_loss: 0.1517 - learning_rate: 0.0037\n\nEpoch 56: LearningRateScheduler setting learning rate to 0.0035875399290983077.\nEpoch 56/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7033 - loss: 0.1437\nEpoch 56: dir_acc did not improve from 0.71187\n\nEpoch 56: val_dir_acc did not improve from 0.70833\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.7033 - loss: 0.1437 - val_dir_acc: 0.7054 - val_loss: 0.1613 - learning_rate: 0.0036\n\nEpoch 57: LearningRateScheduler setting learning rate to 0.00348559745397654.\nEpoch 57/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7075 - loss: 0.1423\nEpoch 57: dir_acc did not improve from 0.71187\n\nEpoch 57: val_dir_acc did not improve from 0.70833\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.7075 - loss: 0.1423 - val_dir_acc: 0.7031 - val_loss: 0.1542 - learning_rate: 0.0035\n\nEpoch 58: LearningRateScheduler setting learning rate to 0.0033816801860829505.\nEpoch 58/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7167 - loss: 0.1377\nEpoch 58: dir_acc improved from 0.71187 to 0.71634, saving model to transformer_train_model.keras\n\nEpoch 58: val_dir_acc improved from 0.70833 to 0.71131, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 154ms/step - dir_acc: 0.7167 - loss: 0.1377 - val_dir_acc: 0.7113 - val_loss: 0.1477 - learning_rate: 0.0034\n\nEpoch 59: LearningRateScheduler setting learning rate to 0.0032759974009654944.\nEpoch 59/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7194 - loss: 0.1322\nEpoch 59: dir_acc improved from 0.71634 to 0.72226, saving model to transformer_train_model.keras\n\nEpoch 59: val_dir_acc improved from 0.71131 to 0.71354, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 154ms/step - dir_acc: 0.7194 - loss: 0.1322 - val_dir_acc: 0.7135 - val_loss: 0.1554 - learning_rate: 0.0033\n\nEpoch 60: LearningRateScheduler setting learning rate to 0.0031687619296888545.\nEpoch 60/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7178 - loss: 0.1351\nEpoch 60: dir_acc did not improve from 0.72226\n\nEpoch 60: val_dir_acc did not improve from 0.71354\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.7178 - loss: 0.1351 - val_dir_acc: 0.7009 - val_loss: 0.1509 - learning_rate: 0.0032\n\nEpoch 61: LearningRateScheduler setting learning rate to 0.003060189730221005.\nEpoch 61/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7160 - loss: 0.1362\nEpoch 61: dir_acc did not improve from 0.72226\n\nEpoch 61: val_dir_acc improved from 0.71354 to 0.71503, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7160 - loss: 0.1361 - val_dir_acc: 0.7150 - val_loss: 0.1414 - learning_rate: 0.0031\n\nEpoch 62: LearningRateScheduler setting learning rate to 0.002950499452522599.\nEpoch 62/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7282 - loss: 0.1283\nEpoch 62: dir_acc did not improve from 0.72226\n\nEpoch 62: val_dir_acc did not improve from 0.71503\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.7282 - loss: 0.1283 - val_dir_acc: 0.6853 - val_loss: 0.1546 - learning_rate: 0.0030\n\nEpoch 63: LearningRateScheduler setting learning rate to 0.0028399119982150506.\nEpoch 63/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7224 - loss: 0.1317\nEpoch 63: dir_acc improved from 0.72226 to 0.72533, saving model to transformer_train_model.keras\n\nEpoch 63: val_dir_acc did not improve from 0.71503\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7224 - loss: 0.1317 - val_dir_acc: 0.6987 - val_loss: 0.1607 - learning_rate: 0.0028\n\nEpoch 64: LearningRateScheduler setting learning rate to 0.002728650075714067.\nEpoch 64/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7296 - loss: 0.1347\nEpoch 64: dir_acc did not improve from 0.72533\n\nEpoch 64: val_dir_acc improved from 0.71503 to 0.75223, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7295 - loss: 0.1347 - val_dir_acc: 0.7522 - val_loss: 0.1403 - learning_rate: 0.0027\n\nEpoch 65: LearningRateScheduler setting learning rate to 0.0026169377517245352.\nEpoch 65/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7247 - loss: 0.1317\nEpoch 65: dir_acc improved from 0.72533 to 0.72848, saving model to transformer_train_model.keras\n\nEpoch 65: val_dir_acc did not improve from 0.75223\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7247 - loss: 0.1316 - val_dir_acc: 0.7009 - val_loss: 0.1365 - learning_rate: 0.0026\n\nEpoch 66: LearningRateScheduler setting learning rate to 0.0025050000000000003.\nEpoch 66/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7583 - loss: 0.1204\nEpoch 66: dir_acc improved from 0.72848 to 0.73451, saving model to transformer_train_model.keras\n\nEpoch 66: val_dir_acc did not improve from 0.75223\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7581 - loss: 0.1205 - val_dir_acc: 0.7180 - val_loss: 0.1377 - learning_rate: 0.0025\n\nEpoch 67: LearningRateScheduler setting learning rate to 0.0023930622482754658.\nEpoch 67/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7356 - loss: 0.1302\nEpoch 67: dir_acc improved from 0.73451 to 0.73665, saving model to transformer_train_model.keras\n\nEpoch 67: val_dir_acc did not improve from 0.75223\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7356 - loss: 0.1301 - val_dir_acc: 0.6942 - val_loss: 0.1377 - learning_rate: 0.0024\n\nEpoch 68: LearningRateScheduler setting learning rate to 0.002281349924285934.\nEpoch 68/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.7282 - loss: 0.1270\nEpoch 68: dir_acc did not improve from 0.73665\n\nEpoch 68: val_dir_acc did not improve from 0.75223\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.7282 - loss: 0.1270 - val_dir_acc: 0.7232 - val_loss: 0.1395 - learning_rate: 0.0023\n\nEpoch 69: LearningRateScheduler setting learning rate to 0.00217008800178495.\nEpoch 69/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7474 - loss: 0.1212\nEpoch 69: dir_acc improved from 0.73665 to 0.74079, saving model to transformer_train_model.keras\n\nEpoch 69: val_dir_acc did not improve from 0.75223\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 150ms/step - dir_acc: 0.7474 - loss: 0.1212 - val_dir_acc: 0.7463 - val_loss: 0.1303 - learning_rate: 0.0022\n\nEpoch 70: LearningRateScheduler setting learning rate to 0.002059500547477402.\nEpoch 70/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7414 - loss: 0.1215\nEpoch 70: dir_acc improved from 0.74079 to 0.74271, saving model to transformer_train_model.keras\n\nEpoch 70: val_dir_acc did not improve from 0.75223\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7414 - loss: 0.1215 - val_dir_acc: 0.6942 - val_loss: 0.1456 - learning_rate: 0.0021\n\nEpoch 71: LearningRateScheduler setting learning rate to 0.001949810269778996.\nEpoch 71/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7273 - loss: 0.1196\nEpoch 71: dir_acc did not improve from 0.74271\n\nEpoch 71: val_dir_acc did not improve from 0.75223\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.7275 - loss: 0.1196 - val_dir_acc: 0.7135 - val_loss: 0.1295 - learning_rate: 0.0019\n\nEpoch 72: LearningRateScheduler setting learning rate to 0.0018412380703111465.\nEpoch 72/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7484 - loss: 0.1159\nEpoch 72: dir_acc improved from 0.74271 to 0.74605, saving model to transformer_train_model.keras\n\nEpoch 72: val_dir_acc did not improve from 0.75223\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7484 - loss: 0.1159 - val_dir_acc: 0.7210 - val_loss: 0.1293 - learning_rate: 0.0018\n\nEpoch 73: LearningRateScheduler setting learning rate to 0.0017340025990345066.\nEpoch 73/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7507 - loss: 0.1188\nEpoch 73: dir_acc improved from 0.74605 to 0.74890, saving model to transformer_train_model.keras\n\nEpoch 73: val_dir_acc did not improve from 0.75223\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7507 - loss: 0.1188 - val_dir_acc: 0.7277 - val_loss: 0.1376 - learning_rate: 0.0017\n\nEpoch 74: LearningRateScheduler setting learning rate to 0.0016283198139170505.\nEpoch 74/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7487 - loss: 0.1187\nEpoch 74: dir_acc improved from 0.74890 to 0.75018, saving model to transformer_train_model.keras\n\nEpoch 74: val_dir_acc did not improve from 0.75223\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7487 - loss: 0.1187 - val_dir_acc: 0.7024 - val_loss: 0.1347 - learning_rate: 0.0016\n\nEpoch 75: LearningRateScheduler setting learning rate to 0.0015244025460234615.\nEpoch 75/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.7470 - loss: 0.1161\nEpoch 75: dir_acc improved from 0.75018 to 0.75126, saving model to transformer_train_model.keras\n\nEpoch 75: val_dir_acc did not improve from 0.75223\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7470 - loss: 0.1161 - val_dir_acc: 0.7500 - val_loss: 0.1270 - learning_rate: 0.0015\n\nEpoch 76: LearningRateScheduler setting learning rate to 0.001422460070901693.\nEpoch 76/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7571 - loss: 0.1137\nEpoch 76: dir_acc improved from 0.75126 to 0.75638, saving model to transformer_train_model.keras\n\nEpoch 76: val_dir_acc improved from 0.75223 to 0.75670, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 154ms/step - dir_acc: 0.7571 - loss: 0.1137 - val_dir_acc: 0.7567 - val_loss: 0.1247 - learning_rate: 0.0014\n\nEpoch 77: LearningRateScheduler setting learning rate to 0.0013226976871298685.\nEpoch 77/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7592 - loss: 0.1099\nEpoch 77: dir_acc improved from 0.75638 to 0.76317, saving model to transformer_train_model.keras\n\nEpoch 77: val_dir_acc improved from 0.75670 to 0.76711, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 153ms/step - dir_acc: 0.7593 - loss: 0.1099 - val_dir_acc: 0.7671 - val_loss: 0.1222 - learning_rate: 0.0013\n\nEpoch 78: LearningRateScheduler setting learning rate to 0.0012253163028722645.\nEpoch 78/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7582 - loss: 0.1143\nEpoch 78: dir_acc did not improve from 0.76317\n\nEpoch 78: val_dir_acc did not improve from 0.76711\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.7582 - loss: 0.1142 - val_dir_acc: 0.7448 - val_loss: 0.1226 - learning_rate: 0.0012\n\nEpoch 79: LearningRateScheduler setting learning rate to 0.0011305120312770046.\nEpoch 79/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7762 - loss: 0.1092\nEpoch 79: dir_acc improved from 0.76317 to 0.76586, saving model to transformer_train_model.keras\n\nEpoch 79: val_dir_acc did not improve from 0.76711\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7761 - loss: 0.1092 - val_dir_acc: 0.7507 - val_loss: 0.1241 - learning_rate: 0.0011\n\nEpoch 80: LearningRateScheduler setting learning rate to 0.00103847579553028.\nEpoch 80/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7727 - loss: 0.1058\nEpoch 80: dir_acc improved from 0.76586 to 0.77101, saving model to transformer_train_model.keras\n\nEpoch 80: val_dir_acc did not improve from 0.76711\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7727 - loss: 0.1059 - val_dir_acc: 0.7656 - val_loss: 0.1238 - learning_rate: 0.0010\n\nEpoch 81: LearningRateScheduler setting learning rate to 0.00094939294436246.\nEpoch 81/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7639 - loss: 0.1099\nEpoch 81: dir_acc did not improve from 0.77101\n\nEpoch 81: val_dir_acc did not improve from 0.76711\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.7639 - loss: 0.1099 - val_dir_acc: 0.7626 - val_loss: 0.1190 - learning_rate: 9.4939e-04\n\nEpoch 82: LearningRateScheduler setting learning rate to 0.0008634428787804172.\nEpoch 82/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7696 - loss: 0.1067\nEpoch 82: dir_acc did not improve from 0.77101\n\nEpoch 82: val_dir_acc did not improve from 0.76711\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.7696 - loss: 0.1067 - val_dir_acc: 0.7403 - val_loss: 0.1173 - learning_rate: 8.6344e-04\n\nEpoch 83: LearningRateScheduler setting learning rate to 0.0007807986907777728.\nEpoch 83/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7681 - loss: 0.1034\nEpoch 83: dir_acc did not improve from 0.77101\n\nEpoch 83: val_dir_acc did not improve from 0.76711\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.7681 - loss: 0.1034 - val_dir_acc: 0.7664 - val_loss: 0.1257 - learning_rate: 7.8080e-04\n\nEpoch 84: LearningRateScheduler setting learning rate to 0.0007016268147506584.\nEpoch 84/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7679 - loss: 0.1049\nEpoch 84: dir_acc improved from 0.77101 to 0.77272, saving model to transformer_train_model.keras\n\nEpoch 84: val_dir_acc improved from 0.76711 to 0.77530, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 154ms/step - dir_acc: 0.7679 - loss: 0.1049 - val_dir_acc: 0.7753 - val_loss: 0.1185 - learning_rate: 7.0163e-04\n\nEpoch 85: LearningRateScheduler setting learning rate to 0.000626086692320991.\nEpoch 85/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7807 - loss: 0.1023\nEpoch 85: dir_acc improved from 0.77272 to 0.77780, saving model to transformer_train_model.keras\n\nEpoch 85: val_dir_acc did not improve from 0.77530\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7807 - loss: 0.1023 - val_dir_acc: 0.7493 - val_loss: 0.1172 - learning_rate: 6.2609e-04\n\nEpoch 86: LearningRateScheduler setting learning rate to 0.0005543304512422657.\nEpoch 86/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7704 - loss: 0.1054\nEpoch 86: dir_acc did not improve from 0.77780\n\nEpoch 86: val_dir_acc did not improve from 0.77530\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 144ms/step - dir_acc: 0.7705 - loss: 0.1054 - val_dir_acc: 0.7731 - val_loss: 0.1153 - learning_rate: 5.5433e-04\n\nEpoch 87: LearningRateScheduler setting learning rate to 0.00048650259903450645.\nEpoch 87/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7729 - loss: 0.1026\nEpoch 87: dir_acc improved from 0.77780 to 0.78059, saving model to transformer_train_model.keras\n\nEpoch 87: val_dir_acc improved from 0.77530 to 0.78051, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 154ms/step - dir_acc: 0.7730 - loss: 0.1026 - val_dir_acc: 0.7805 - val_loss: 0.1143 - learning_rate: 4.8650e-04\n\nEpoch 88: LearningRateScheduler setting learning rate to 0.00042273973196535.\nEpoch 88/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7790 - loss: 0.1041\nEpoch 88: dir_acc improved from 0.78059 to 0.78488, saving model to transformer_train_model.keras\n\nEpoch 88: val_dir_acc did not improve from 0.78051\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7791 - loss: 0.1041 - val_dir_acc: 0.7641 - val_loss: 0.1151 - learning_rate: 4.2274e-04\n\nEpoch 89: LearningRateScheduler setting learning rate to 0.00036317025996334415.\nEpoch 89/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7869 - loss: 0.0986\nEpoch 89: dir_acc did not improve from 0.78488\n\nEpoch 89: val_dir_acc improved from 0.78051 to 0.78125, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7868 - loss: 0.0986 - val_dir_acc: 0.7812 - val_loss: 0.1135 - learning_rate: 3.6317e-04\n\nEpoch 90: LearningRateScheduler setting learning rate to 0.00030791414801743875.\nEpoch 90/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7841 - loss: 0.0985\nEpoch 90: dir_acc improved from 0.78488 to 0.78860, saving model to transformer_train_model.keras\n\nEpoch 90: val_dir_acc did not improve from 0.78125\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7841 - loss: 0.0985 - val_dir_acc: 0.7664 - val_loss: 0.1135 - learning_rate: 3.0791e-04\n\nEpoch 91: LearningRateScheduler setting learning rate to 0.00025708267458346456.\nEpoch 91/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7789 - loss: 0.0990\nEpoch 91: dir_acc did not improve from 0.78860\n\nEpoch 91: val_dir_acc did not improve from 0.78125\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 144ms/step - dir_acc: 0.7789 - loss: 0.0990 - val_dir_acc: 0.7716 - val_loss: 0.1133 - learning_rate: 2.5708e-04\n\nEpoch 92: LearningRateScheduler setting learning rate to 0.00021077820748413085.\nEpoch 92/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7963 - loss: 0.0972\nEpoch 92: dir_acc improved from 0.78860 to 0.79133, saving model to transformer_train_model.keras\n\nEpoch 92: val_dir_acc improved from 0.78125 to 0.79018, saving model to transformer_val_model.keras\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 154ms/step - dir_acc: 0.7962 - loss: 0.0972 - val_dir_acc: 0.7902 - val_loss: 0.1128 - learning_rate: 2.1078e-04\n\nEpoch 93: LearningRateScheduler setting learning rate to 0.00016909399775385568.\nEpoch 93/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7927 - loss: 0.0999\nEpoch 93: dir_acc did not improve from 0.79133\n\nEpoch 93: val_dir_acc did not improve from 0.79018\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.7927 - loss: 0.0999 - val_dir_acc: 0.7686 - val_loss: 0.1115 - learning_rate: 1.6909e-04\n\nEpoch 94: LearningRateScheduler setting learning rate to 0.00013211399184359196.\nEpoch 94/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7858 - loss: 0.0962\nEpoch 94: dir_acc did not improve from 0.79133\n\nEpoch 94: val_dir_acc did not improve from 0.79018\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.7858 - loss: 0.0962 - val_dir_acc: 0.7478 - val_loss: 0.1109 - learning_rate: 1.3211e-04\n\nEpoch 95: LearningRateScheduler setting learning rate to 9.991266256384617e-05.\nEpoch 95/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7785 - loss: 0.0975\nEpoch 95: dir_acc did not improve from 0.79133\n\nEpoch 95: val_dir_acc did not improve from 0.79018\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 144ms/step - dir_acc: 0.7786 - loss: 0.0975 - val_dir_acc: 0.7597 - val_loss: 0.1108 - learning_rate: 9.9913e-05\n\nEpoch 96: LearningRateScheduler setting learning rate to 7.255485910635008e-05.\nEpoch 96/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - dir_acc: 0.7909 - loss: 0.0981\nEpoch 96: dir_acc did not improve from 0.79133\n\nEpoch 96: val_dir_acc did not improve from 0.79018\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.7909 - loss: 0.0981 - val_dir_acc: 0.7664 - val_loss: 0.1105 - learning_rate: 7.2555e-05\n\nEpoch 97: LearningRateScheduler setting learning rate to 5.009567644641898e-05.\nEpoch 97/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7966 - loss: 0.0943\nEpoch 97: dir_acc improved from 0.79133 to 0.79727, saving model to transformer_train_model.keras\n\nEpoch 97: val_dir_acc did not improve from 0.79018\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - dir_acc: 0.7966 - loss: 0.0943 - val_dir_acc: 0.7820 - val_loss: 0.1110 - learning_rate: 5.0096e-05\n\nEpoch 98: LearningRateScheduler setting learning rate to 3.258034438900293e-05.\nEpoch 98/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7895 - loss: 0.0946\nEpoch 98: dir_acc did not improve from 0.79727\n\nEpoch 98: val_dir_acc did not improve from 0.79018\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 144ms/step - dir_acc: 0.7896 - loss: 0.0946 - val_dir_acc: 0.7656 - val_loss: 0.1107 - learning_rate: 3.2580e-05\n\nEpoch 99: LearningRateScheduler setting learning rate to 2.0044136481878526e-05.\nEpoch 99/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7915 - loss: 0.0958\nEpoch 99: dir_acc did not improve from 0.79727\n\nEpoch 99: val_dir_acc did not improve from 0.79018\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.7915 - loss: 0.0958 - val_dir_acc: 0.7820 - val_loss: 0.1106 - learning_rate: 2.0044e-05\n\nEpoch 100: LearningRateScheduler setting learning rate to 1.25122989794201e-05.\nEpoch 100/100\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - dir_acc: 0.7885 - loss: 0.0948\nEpoch 100: dir_acc did not improve from 0.79727\n\nEpoch 100: val_dir_acc did not improve from 0.79018\n\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - dir_acc: 0.7885 - loss: 0.0949 - val_dir_acc: 0.7545 - val_loss: 0.1099 - learning_rate: 1.2512e-05\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7ea6c1f51360>"},"metadata":{}}]},{"cell_type":"code","source":"# Load Weights\nmodel.load_weights(\"transformer_val_model.keras\")\n\n# Make predictions\naccuracy = model.evaluate(test_sequences, test_labels)[1]\nprint(accuracy)\n\n# Calculate additional metrics as needed\nfrom sklearn.metrics import r2_score\n\npredictions = model.predict(test_sequences)\nprint(test_labels.shape)\nr2 = r2_score(test_labels[:, 1], predictions[:, 0])\nprint(f\"R-squared: {r2}\")","metadata":{"id":"gFpSqzgXCE4K","execution":{"iopub.status.busy":"2024-06-19T03:24:01.242170Z","iopub.execute_input":"2024-06-19T03:24:01.242542Z","iopub.status.idle":"2024-06-19T03:24:03.391956Z","shell.execute_reply.started":"2024-06-19T03:24:01.242517Z","shell.execute_reply":"2024-06-19T03:24:03.390846Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - dir_acc: 0.8028 - loss: 0.1009\n0.8065828084945679\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n(397, 4)\nR-squared: 0.9806653884139327\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"ZxtuorRiS9qa"},"execution_count":null,"outputs":[]}]}